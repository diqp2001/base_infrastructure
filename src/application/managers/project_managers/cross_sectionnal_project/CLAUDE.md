# CLAUDE.md â€“ Test Base Project Manager

## ğŸ¯ Purpose

The **Test Base Project Manager** is a comprehensive trading system that combines sophisticated spatiotemporal momentum modeling with robust factor creation, data storage, and backtesting capabilities. This project serves as a hybrid architecture that brings together the best aspects of three existing project managers to create a complete end-to-end trading pipeline.

## ğŸ§¬ Inspiration & Architecture Fusion

This project strategically combines elements from three foundational managers:

### 1. **Spatiotemporal Momentum Manager** (Core Logic & Flow)
- **Primary Inspiration**: Main algorithmic logic and pipeline architecture
- **Key Elements Adopted**:
  - Multi-asset time series processing with `[timesteps, features, assets]` input shape
  - TFT (Temporal Fusion Transformer) and MLP model management
  - Multivariate/univariate tensor creation and train-validation-test splitting
  - Momentum-based feature engineering (deep momentum, MACD signals)
  - Rolling window training with temporal integrity (no lookahead bias)
  - Advanced loss functions: Sharpe loss, L1 regularization, turnover penalty

### 2. **Test Project Factor Creation** (Data Extraction & Storage)
- **Enhancement Purpose**: Robust data management and factor architecture
- **Key Elements Integrated**:
  - Comprehensive factor definition framework (price, volume, technical indicators)
  - Database-backed factor storage with validation rules
  - CSV data ingestion and historical data population
  - Factor repository pattern with bulk operations
  - Entity-factor relationship management
  - Real-time factor value calculation and persistence

### 3. **Test Project Backtest** (Backtesting & Web Integration)
- **Enhancement Purpose**: Live backtesting engine with web interface
- **Key Elements Incorporated**:
  - Misbuffet backtesting framework integration
  - Web interface for real-time backtest monitoring
  - Progress tracking and result visualization
  - Black-Litterman portfolio optimization
  - Algorithm lifecycle management (initialization, data handling, execution)
  - Performance analytics and result persistence

## ğŸ—ï¸ Overall Architecture & Folder Structure

```
src/application/managers/project_managers/test_base_project/
â”œâ”€â”€ CLAUDE.md                           # This documentation file
â”œâ”€â”€ __init__.py                         # Package initialization
â”œâ”€â”€ config.py                           # Database and system configuration
â”œâ”€â”€ test_base_project_manager.py        # Main manager class
â”œâ”€â”€ 
â”œâ”€â”€ data/                               # Data processing components
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ data_loader.py                  # CSV/database data loading
â”‚   â”œâ”€â”€ feature_engineer.py            # Spatiotemporal feature creation
â”‚   â””â”€â”€ factor_manager.py               # Factor definition and storage
â”‚
â”œâ”€â”€ models/                             # ML model components
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ spatiotemporal_model.py         # TFT/MLP model wrapper
â”‚   â”œâ”€â”€ model_trainer.py               # Training pipeline
â”‚   â””â”€â”€ tensor_splitter.py              # Multivariate/univariate splitting
â”‚
â”œâ”€â”€ strategy/                           # Trading strategy components
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ momentum_strategy.py            # Core momentum strategy
â”‚   â”œâ”€â”€ portfolio_optimizer.py          # Black-Litterman optimization
â”‚   â””â”€â”€ signal_generator.py             # ML-based signal generation
â”‚
â”œâ”€â”€ backtesting/                        # Backtesting engine components
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ backtest_engine.py              # Misbuffet integration
â”‚   â”œâ”€â”€ algorithm.py                    # QCAlgorithm implementation
â”‚   â”œâ”€â”€ engine_config.py                # Backtest configuration
â”‚   â””â”€â”€ launch_config.py                # Launcher configuration
â”‚
â”œâ”€â”€ web/                                # Web interface components
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ web_interface.py                # Flask-based monitoring
â”‚   â”œâ”€â”€ progress_tracker.py             # Real-time progress updates
â”‚   â””â”€â”€ result_visualizer.py            # Performance charts
â”‚
â””â”€â”€ utils/                              # Utility components
    â”œâ”€â”€ __init__.py
    â”œâ”€â”€ loss_functions.py               # Custom loss functions (Sharpe, turnover)
    â”œâ”€â”€ validators.py                   # Data validation utilities
    â””â”€â”€ performance_metrics.py          # Performance calculation utilities
```

## ğŸ”„ Project Flow & Pipeline Stages

### Stage 1: **Data Loading & Factor Creation**
*Inspired by: test_project_factor_creation*

1. **Entity Creation**
   - Initialize database tables for companies and currencies
   - Create CompanyShare entities for target universe (AAPL, MSFT, AMZN, GOOGL)
   - Set up factor definitions (OHLCV, technical indicators, momentum features)

2. **Historical Data Ingestion**
   - Load CSV stock data from file system
   - Populate factor values in database
   - Create factor validation rules
   - Establish factor-entity relationships

3. **Feature Engineering**
   - Generate deep momentum features (multi-timeframe returns)
   - Calculate MACD signals across different periods
   - Create volatility and technical indicators
   - Store engineered features as factors

### Stage 2: **Model Training & Spatiotemporal Processing**
*Inspired by: spatiotemporal_momentum_manager*

4. **Data Preprocessing**
   - Retrieve factor data for model training
   - Create multivariate/univariate tensor structures
   - Apply temporal train-validation-test splits
   - Handle missing data and scaling

5. **Model Training**
   - Train TFT models for complex temporal patterns
   - Train MLP models for simpler feature relationships
   - Use custom loss functions (Sharpe ratio optimization)
   - Apply regularization (L1, turnover penalty)

6. **Model Validation**
   - Rolling window cross-validation
   - Performance evaluation on validation sets
   - Model selection and hyperparameter optimization

### Stage 3: **Backtesting & Web Integration**
*Inspired by: test_project_backtest*

7. **Algorithm Implementation**
   - Create QCAlgorithm with spatiotemporal model integration
   - Implement signal generation from trained models
   - Apply Black-Litterman portfolio optimization
   - Execute trades based on optimized weights

8. **Backtest Execution**
   - Launch Misbuffet backtesting engine
   - Run algorithm with historical data
   - Track performance and risk metrics
   - Handle transaction costs and slippage

9. **Web Interface & Monitoring**
   - Start Flask web interface
   - Provide real-time progress updates
   - Display performance charts and metrics
   - Enable parameter adjustment and re-runs

## ğŸ”§ Component Integration & Reused Elements

### From Spatiotemporal Momentum Manager:
- **Reused**: `SpatioTemporalMomentumManager` class architecture
- **Adapted**: Feature engineering methods (`add_deep_momentum_features`, `add_macd_signal_features`)
- **Enhanced**: Model training pipeline with factor-based data retrieval
- **Integrated**: Loss functions (`sharpe_loss`, `reg_turnover`, `reg_l1`)

### From Test Project Factor Creation:
- **Reused**: Factor repository pattern and database schema
- **Adapted**: Entity creation with bulk operations
- **Enhanced**: Factor definitions to include spatiotemporal features
- **Integrated**: Real-time factor calculation during backtesting

### From Test Project Backtest:
- **Reused**: Misbuffet framework integration
- **Adapted**: Algorithm class with ML model integration
- **Enhanced**: Web interface with factor system monitoring
- **Integrated**: Performance tracking with factor-based analytics

### MLflow Experiment Tracking Integration:
- **Experiment Management**: Automatic experiment creation and run management
- **Parameter Logging**: Complete simulation parameters (tickers, dates, model types, capital)
- **Metrics Tracking**: Performance metrics (Sharpe ratio, returns, drawdown, execution time)
- **Artifact Storage**: Model info, simulation results, and configuration files
- **Stage-wise Tracking**: Factor setup, model training, and backtesting metrics
- **Error Handling**: Proper MLflow run cleanup and error state logging

## ğŸ“Š Expected Functions & Classes

### Core Manager Class
```python
class TestBaseProjectManager(ProjectManager):
    """
    Main project manager combining spatiotemporal modeling,
    factor creation, and backtesting capabilities.
    """
    def __init__(self)
    def setup_factor_system(self) -> Dict[str, Any]
    def create_entities_and_factors(self) -> Dict[str, Any]
    def train_spatiotemporal_models(self) -> Dict[str, Any]
    def run_backtest_with_web_interface(self) -> Dict[str, Any]
    def get_comprehensive_results(self) -> Dict[str, Any]
```

### Data Processing Components
```python
class SpatiotemporalDataLoader:
    def load_historical_data_with_factors(self) -> pd.DataFrame
    def prepare_multivariate_tensors(self) -> MultivariateTrainValTestSplitterService
    def create_factor_features(self) -> pd.DataFrame

class FactorEnginedDataManager:
    def populate_momentum_factors(self)
    def calculate_technical_indicators(self)
    def store_engineered_factors(self)
```

### Model Components
```python
class HybridSpatiotemporalModel:
    def train_tft_with_factors(self)
    def train_mlp_with_factors(self)
    def generate_signals_from_factors(self)

class PortfolioOptimizer:
    def apply_black_litterman_with_signals(self)
    def optimize_weights_with_risk_constraints(self)
```

### Backtesting Components
```python
class FactorBacktestAlgorithm(QCAlgorithm):
    def initialize_with_factor_system(self)
    def on_data_with_factor_updates(self)
    def execute_spatiotemporal_strategy(self)

class WebBacktestManager:
    def start_web_interface_with_factors(self)
    def track_factor_performance(self)
    def visualize_spatiotemporal_results(self)
```

## ğŸ”— Component Connections & Data Flow

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   CSV Data      â”‚â”€â”€â”€â–¶â”‚  Factor System   â”‚â”€â”€â”€â–¶â”‚ Spatiotemporal  â”‚
â”‚   Loading       â”‚    â”‚  Creation        â”‚    â”‚ Feature Eng.    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                       â”‚                       â”‚
         â–¼                       â–¼                       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Database      â”‚â—€â”€â”€â”€â”‚  Factor Values   â”‚â”€â”€â”€â–¶â”‚ Model Training  â”‚
â”‚   Storage       â”‚    â”‚  Population      â”‚    â”‚ (TFT/MLP)       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                       â”‚                       â”‚
         â–¼                       â–¼                       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Web Interface  â”‚â—€â”€â”€â”€â”‚  Backtest Engine â”‚â—€â”€â”€â”€â”‚ Signal          â”‚
â”‚  Monitoring     â”‚    â”‚  (Misbuffet)     â”‚    â”‚ Generation      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸš€ Future Improvements & Scalability

### Phase 1: Enhanced Model Architecture
- **Multi-Model Ensemble**: Combine TFT, LSTM, and Transformer models
- **Dynamic Feature Selection**: Automated feature importance ranking
- **Regime Detection**: Market state classification for adaptive strategies
- **Alternative Data Integration**: News sentiment, options flow, earnings data

### Phase 2: Advanced Portfolio Management
- **Multi-Asset Support**: Extend beyond equities (FX, commodities, crypto)
- **Risk Parity Integration**: Complement Black-Litterman with risk budgeting
- **Dynamic Hedging**: Automated hedge ratio calculation and execution
- **ESG Factor Integration**: Sustainability and governance factors

### Phase 3: Production Infrastructure
- **Real-Time Data Feeds**: WebSocket integration for live market data
- **Microservices Architecture**: Decompose into scalable services
- **Cloud Deployment**: AWS/GCP with auto-scaling capabilities
- **API Gateway**: RESTful API for external system integration

### Phase 4: Advanced Analytics
- **Reinforcement Learning**: Q-learning for dynamic strategy adaptation
- **Explainable AI**: SHAP/LIME integration for model interpretability
- **Stress Testing**: Monte Carlo scenario analysis
- **Performance Attribution**: Factor-based return decomposition

### Phase 5: User Experience
- **Mobile Application**: iOS/Android trading companion
- **Voice Interface**: Alexa/Google Assistant integration
- **Automated Reporting**: Daily/weekly performance summaries
- **Social Trading**: Strategy sharing and ranking platform

## ğŸ›ï¸ Configuration & Customization

### Model Configuration
- **TFT Parameters**: Attention heads, hidden dimensions, encoder/decoder lengths
- **Training Parameters**: Learning rates, batch sizes, early stopping criteria
- **Feature Selection**: Enable/disable specific factor groups
- **Risk Parameters**: Maximum position sizes, sector concentration limits

### Backtesting Configuration
- **Time Periods**: Start/end dates, warm-up periods, out-of-sample testing
- **Transaction Costs**: Commission structures, bid-ask spreads, market impact
- **Data Frequency**: Daily, hourly, minute-level backtesting
- **Benchmark Selection**: Custom benchmark or standard indices

### Web Interface Configuration
- **Dashboard Layout**: Customizable chart arrangements and metrics
- **Alert Settings**: Performance thresholds and notification preferences
- **Export Options**: PDF reports, CSV data downloads
- **User Permissions**: Role-based access to different system components

### MLflow Tracking Configuration
- **Experiment Name**: `test_base_project_manager` (configurable)
- **Tracking URI**: Local `mlruns` directory (can be set to remote MLflow server)
- **Auto-logging**: Automatic parameter, metric, and artifact logging for each simulation
- **Run Naming**: Timestamp-based run names with optional custom naming
- **Artifact Types**: JSON results, model information, configuration files
- **Metric Categories**: Performance metrics, timing metrics, success/failure indicators

---

## ğŸ“ˆ Expected Outcomes

This integrated system will provide:

1. **Robust Factor Infrastructure**: Scalable factor creation, storage, and retrieval
2. **Advanced ML Models**: State-of-the-art spatiotemporal modeling capabilities  
3. **Professional Backtesting**: Industry-standard backtesting with realistic constraints
4. **Real-Time Monitoring**: Web-based interface for live system monitoring
5. **Comprehensive Analytics**: Detailed performance attribution and risk analysis
6. **Production Readiness**: Architecture designed for scaling to live trading
7. **Experiment Tracking**: MLflow integration for reproducible simulation runs and model versioning

The Test Base Project Manager represents a significant evolution from its constituent components, creating a unified platform that bridges research, development, and production trading system requirements.

---

## ğŸ“Š MLflow Integration Usage

### Basic Usage
```python
# Initialize the manager (MLflow setup happens automatically)
manager = TestBaseProjectManager()

# Run simulation with automatic MLflow tracking
results = manager.run(
    tickers=['AAPL', 'MSFT', 'GOOGL'],
    initial_capital=100000,
    model_type='both',
    launch_web_interface=True
)

# All parameters, metrics, and artifacts are automatically logged
```

### Accessing MLflow UI
```bash
# View experiment results in MLflow UI
mlflow ui --backend-store-uri ./mlruns

# Navigate to http://localhost:5000 to view experiments
```

### Tracked Information
- **Parameters**: Tickers, capital, model types, dates, configurations
- **Metrics**: Portfolio value, returns, Sharpe ratio, max drawdown, execution time
- **Artifacts**: Simulation results JSON, model information, configuration files
- **Tags**: Run status (success/failed/error), error messages
- **Models**: Trained model artifacts and metadata (when available)